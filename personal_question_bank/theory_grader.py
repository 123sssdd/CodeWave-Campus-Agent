#!/usr/bin/env python3
"""
ç†è®ºé¢˜å’Œç®€ç­”é¢˜æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ
æ”¯æŒå…³é”®è¯åŒ¹é…ã€éƒ¨åˆ†è¯„åˆ†ã€è¯¦ç»†åé¦ˆå’Œé¼“åŠ±æ€§è¯„è¯­
"""

import re
import jieba
import difflib
from typing import List, Dict, Tuple
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class GradingResult:
    """è¯„åˆ†ç»“æœ"""
    score: float  # 0-1ä¹‹é—´çš„åˆ†æ•°
    is_correct: bool  # æ˜¯å¦å®Œå…¨æ­£ç¡®
    feedback: str  # è¯¦ç»†åé¦ˆ
    correct_keywords: List[str]  # ç­”å¯¹çš„å…³é”®è¯
    missing_keywords: List[str]  # é—æ¼çš„å…³é”®è¯
    incorrect_parts: List[str]  # é”™è¯¯çš„éƒ¨åˆ†
    encouragement: str  # é¼“åŠ±æ€§è¯„è¯­

class TheoryQuestionGrader:
    """ç†è®ºé¢˜è¯„åˆ†å™¨"""
    
    def __init__(self):
        # åŒä¹‰è¯è¯å…¸ï¼Œç”¨äºå…³é”®è¯åŒ¹é…
        self.synonyms = {
            # æ•°æ®ç»“æ„ç›¸å…³
            "æ•°ç»„": ["åˆ—è¡¨", "array", "list"],
            "é“¾è¡¨": ["linked list", "é“¾å¼ç»“æ„"],
            "æ ˆ": ["stack", "å †æ ˆ"],
            "é˜Ÿåˆ—": ["queue"],
            "æ ‘": ["tree", "äºŒå‰æ ‘"],
            "å›¾": ["graph"],
            "å“ˆå¸Œè¡¨": ["æ•£åˆ—è¡¨", "hash table", "hash map", "æ˜ å°„"],
            
            # ç®—æ³•ç›¸å…³
            "æ—¶é—´å¤æ‚åº¦": ["æ—¶é—´å¼€é”€", "è¿è¡Œæ—¶é—´"],
            "ç©ºé—´å¤æ‚åº¦": ["ç©ºé—´å¼€é”€", "å†…å­˜å¼€é”€"],
            "é€’å½’": ["é€’å½’è°ƒç”¨", "recursion"],
            "è¿­ä»£": ["å¾ªç¯", "iteration", "loop"],
            "æ’åº": ["sort", "sorting"],
            "æœç´¢": ["æŸ¥æ‰¾", "search"],
            
            # ç¼–ç¨‹æ¦‚å¿µ
            "é¢å‘å¯¹è±¡": ["oop", "object-oriented"],
            "å°è£…": ["encapsulation"],
            "ç»§æ‰¿": ["inheritance"],
            "å¤šæ€": ["polymorphism"],
            "å‡½æ•°": ["æ–¹æ³•", "function", "method"],
            "å˜é‡": ["variable"],
            "å¸¸é‡": ["constant"],
            
            # æ€§èƒ½ç›¸å…³
            "ä¼˜åŒ–": ["æ”¹è¿›", "æå‡", "optimization"],
            "æ•ˆç‡": ["æ€§èƒ½", "performance"],
            "å¿«é€Ÿ": ["é«˜æ•ˆ", "fast", "efficient"],
            "æ…¢": ["ä½æ•ˆ", "slow", "inefficient"]
        }
        
        # é¼“åŠ±æ€§è¯„è¯­æ¨¡æ¿
        self.encouragements = {
            "excellent": [
                "å›ç­”éå¸¸ç²¾å½©ï¼ä½ å¯¹è¿™ä¸ªæ¦‚å¿µçš„ç†è§£å¾ˆæ·±å…¥ã€‚",
                "å¤ªæ£’äº†ï¼ä½ çš„åˆ†æå¾ˆåˆ°ä½ï¼Œå±•ç°äº†æ‰å®çš„åŸºç¡€çŸ¥è¯†ã€‚",
                "å®Œç¾çš„å›ç­”ï¼ç»§ç»­ä¿æŒè¿™æ ·çš„å­¦ä¹ çŠ¶æ€ã€‚"
            ],
            "good": [
                "å¾ˆå¥½çš„å›ç­”ï¼ä½ æŒæ¡äº†å¤§éƒ¨åˆ†è¦ç‚¹ã€‚",
                "ä¸é”™çš„ç†è§£ï¼åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­æ·±å…¥ä¼šæ›´å¥½ã€‚",
                "å›ç­”å¾—å¾ˆå¥½ï¼Œç»§ç»­åŠªåŠ›å®Œå–„ç»†èŠ‚éƒ¨åˆ†ã€‚"
            ],
            "partial": [
                "ä½ çš„ç†è§£æ–¹å‘æ˜¯å¯¹çš„ï¼Œä½†è¿˜éœ€è¦è¡¥å……ä¸€äº›è¦ç‚¹ã€‚",
                "æœ‰ä¸€å®šçš„ç†è§£åŸºç¡€ï¼Œç»§ç»­å­¦ä¹ ä¼šæœ‰å¾ˆå¤§æå‡ã€‚",
                "å›ç­”ä¸­æœ‰æ­£ç¡®çš„éƒ¨åˆ†ï¼ŒåŠ æ²¹å®Œå–„å…¶ä»–æ–¹é¢ï¼"
            ],
            "poor": [
                "çœ‹èµ·æ¥éœ€è¦åŠ å¼ºè¿™éƒ¨åˆ†çš„å­¦ä¹ ï¼Œå»ºè®®é‡æ–°å¤ä¹ ç›¸å…³æ¦‚å¿µã€‚",
                "åˆ«ç°å¿ƒï¼æ¯ä¸ªäººéƒ½æœ‰å­¦ä¹ çš„è¿‡ç¨‹ï¼Œå¤šç»ƒä¹ å°±ä¼šè¿›æ­¥ã€‚",
                "è¿™ä¸ªæ¦‚å¿µç¡®å®æœ‰éš¾åº¦ï¼Œå»ºè®®å…ˆä»åŸºç¡€å¼€å§‹é€æ­¥ç†è§£ã€‚"
            ]
        }
    
    def grade_theory_question(self, user_answer: str, correct_answer: str, 
                            question_content: str = "") -> GradingResult:
        """
        è¯„åˆ†ç†è®ºé¢˜
        
        Args:
            user_answer: ç”¨æˆ·ç­”æ¡ˆ
            correct_answer: æ ‡å‡†ç­”æ¡ˆ
            question_content: é¢˜ç›®å†…å®¹ï¼ˆç”¨äºä¸Šä¸‹æ–‡ç†è§£ï¼‰
            
        Returns:
            GradingResult: è¯¦ç»†çš„è¯„åˆ†ç»“æœ
        """
        # é¢„å¤„ç†ç­”æ¡ˆ
        user_clean = self._clean_text(user_answer)
        correct_clean = self._clean_text(correct_answer)
        
        if not user_clean:
            return GradingResult(
                score=0.0,
                is_correct=False,
                feedback="å›ç­”ä¸èƒ½ä¸ºç©ºï¼Œè¯·æä¾›ä½ çš„ç†è§£å’Œæƒ³æ³•ã€‚",
                correct_keywords=[],
                missing_keywords=self._extract_keywords(correct_clean),
                incorrect_parts=[],
                encouragement="åˆ«æ‹…å¿ƒï¼Œå¼€å§‹æ€è€ƒå’Œè¡¨è¾¾å°±æ˜¯å­¦ä¹ çš„ç¬¬ä¸€æ­¥ï¼"
            )
        
        # æå–å…³é”®è¯
        user_keywords = self._extract_keywords(user_clean)
        correct_keywords = self._extract_keywords(correct_clean)
        
        # åŒ¹é…å…³é”®è¯
        matched_keywords, missing_keywords = self._match_keywords(
            user_keywords, correct_keywords
        )
        
        # è®¡ç®—åŸºç¡€åˆ†æ•°
        base_score = len(matched_keywords) / len(correct_keywords) if correct_keywords else 0
        
        # è¯­ä¹‰ç›¸ä¼¼åº¦åŠ åˆ†
        similarity_score = self._calculate_similarity(user_clean, correct_clean)
        
        # ç»¼åˆåˆ†æ•°
        final_score = min(base_score * 0.7 + similarity_score * 0.3, 1.0)
        
        # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
        incorrect_parts = self._find_incorrect_parts(user_clean, correct_clean)
        
        # ç”Ÿæˆåé¦ˆ
        feedback = self._generate_feedback(
            matched_keywords, missing_keywords, incorrect_parts, final_score
        )
        
        # ç”Ÿæˆé¼“åŠ±æ€§è¯„è¯­
        encouragement = self._generate_encouragement(final_score)
        
        return GradingResult(
            score=final_score,
            is_correct=final_score >= 0.8,
            feedback=feedback,
            correct_keywords=matched_keywords,
            missing_keywords=missing_keywords,
            incorrect_parts=incorrect_parts,
            encouragement=encouragement
        )
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text.strip())
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡æ ‡ç‚¹çš„è¯­ä¹‰ï¼‰
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
        return text.lower()
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        if not text:
            return []
        
        # ä½¿ç”¨jiebaåˆ†è¯
        words = jieba.lcut(text)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'è€Œ', 'å› ä¸º', 'æ‰€ä»¥', 
                     'å¯ä»¥', 'èƒ½å¤Ÿ', 'å°±æ˜¯', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä¸€ä¸ª', 'ä¸€ç§', 'è¿™ç§', 'é‚£ç§',
                     'the', 'is', 'are', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 
                     'for', 'of', 'with', 'by', 'from', 'as', 'an', 'a'}
        
        keywords = []
        for word in words:
            word = word.strip()
            if len(word) > 1 and word not in stop_words:
                keywords.append(word)
        
        return keywords
    
    def _match_keywords(self, user_keywords: List[str], 
                       correct_keywords: List[str]) -> Tuple[List[str], List[str]]:
        """åŒ¹é…å…³é”®è¯ï¼Œè€ƒè™‘åŒä¹‰è¯"""
        matched = []
        missing = []
        
        # åˆ›å»ºç”¨æˆ·å…³é”®è¯çš„æ ‡å‡†åŒ–ç‰ˆæœ¬
        user_normalized = set()
        for keyword in user_keywords:
            user_normalized.add(keyword)
            # æ·»åŠ åŒä¹‰è¯
            for standard, synonyms in self.synonyms.items():
                if keyword in synonyms or keyword == standard:
                    user_normalized.add(standard)
                    user_normalized.update(synonyms)
        
        # æ£€æŸ¥æ¯ä¸ªæ­£ç¡®ç­”æ¡ˆçš„å…³é”®è¯
        for correct_keyword in correct_keywords:
            found = False
            
            # ç›´æ¥åŒ¹é…
            if correct_keyword in user_normalized:
                matched.append(correct_keyword)
                found = True
            else:
                # åŒä¹‰è¯åŒ¹é…
                for standard, synonyms in self.synonyms.items():
                    if correct_keyword == standard or correct_keyword in synonyms:
                        if standard in user_normalized:
                            matched.append(correct_keyword)
                            found = True
                            break
                        for synonym in synonyms:
                            if synonym in user_normalized:
                                matched.append(correct_keyword)
                                found = True
                                break
                    if found:
                        break
                
                # æ¨¡ç³ŠåŒ¹é…ï¼ˆç¼–è¾‘è·ç¦»ï¼‰
                if not found:
                    for user_keyword in user_keywords:
                        similarity = difflib.SequenceMatcher(None, correct_keyword, user_keyword).ratio()
                        if similarity > 0.8:  # 80%ç›¸ä¼¼åº¦
                            matched.append(correct_keyword)
                            found = True
                            break
            
            if not found:
                missing.append(correct_keyword)
        
        return matched, missing
    
    def _calculate_similarity(self, user_text: str, correct_text: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        if not user_text or not correct_text:
            return 0.0
        
        # ä½¿ç”¨difflibè®¡ç®—åºåˆ—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, user_text, correct_text).ratio()
        return similarity
    
    def _find_incorrect_parts(self, user_text: str, correct_text: str) -> List[str]:
        """æ‰¾å‡ºå¯èƒ½é”™è¯¯çš„éƒ¨åˆ†"""
        user_keywords = set(self._extract_keywords(user_text))
        correct_keywords = set(self._extract_keywords(correct_text))
        
        # æ‰¾å‡ºç”¨æˆ·ç­”æ¡ˆä¸­å¯èƒ½é”™è¯¯çš„å…³é”®è¯
        incorrect = []
        
        # ä¸€äº›æ˜æ˜¾é”™è¯¯çš„æ¦‚å¿µå¯¹
        contradictions = {
            "æ ˆ": ["å…ˆè¿›å…ˆå‡º", "fifo"],
            "é˜Ÿåˆ—": ["åè¿›å…ˆå‡º", "lifo"],
            "æ•°ç»„": ["ä¸è¿ç»­", "é“¾å¼"],
            "é“¾è¡¨": ["è¿ç»­å­˜å‚¨", "éšæœºè®¿é—®"],
            "é€’å½’": ["å¾ªç¯", "è¿­ä»£"],
        }
        
        for keyword in user_keywords:
            for correct_concept, wrong_concepts in contradictions.items():
                if correct_concept in correct_keywords and keyword in wrong_concepts:
                    incorrect.append(f"'{keyword}'ä¸'{correct_concept}'çš„ç‰¹æ€§ä¸ç¬¦")
        
        return incorrect
    
    def _generate_feedback(self, matched_keywords: List[str], missing_keywords: List[str],
                          incorrect_parts: List[str], score: float) -> str:
        """ç”Ÿæˆè¯¦ç»†åé¦ˆ"""
        feedback_parts = []
        
        # æ­£ç¡®éƒ¨åˆ†çš„åé¦ˆ
        if matched_keywords:
            feedback_parts.append(f"âœ… ç­”å¯¹çš„è¦ç‚¹ï¼š{', '.join(matched_keywords[:5])}")  # åªæ˜¾ç¤ºå‰5ä¸ª
            if len(matched_keywords) > 5:
                feedback_parts.append(f"   ï¼ˆè¿˜æœ‰{len(matched_keywords)-5}ä¸ªè¦ç‚¹ç­”å¯¹äº†ï¼‰")
        
        # é—æ¼éƒ¨åˆ†çš„åé¦ˆ
        if missing_keywords:
            feedback_parts.append(f"â“ é—æ¼çš„è¦ç‚¹ï¼š{', '.join(missing_keywords[:3])}")  # åªæ˜¾ç¤ºå‰3ä¸ª
            if len(missing_keywords) > 3:
                feedback_parts.append(f"   ï¼ˆè¿˜éœ€è¦è¡¥å……{len(missing_keywords)-3}ä¸ªè¦ç‚¹ï¼‰")
        
        # é”™è¯¯éƒ¨åˆ†çš„åé¦ˆ
        if incorrect_parts:
            feedback_parts.append(f"âŒ éœ€è¦ä¿®æ­£ï¼š{'; '.join(incorrect_parts)}")
        
        # æ€»ä½“è¯„ä»·
        if score >= 0.9:
            feedback_parts.append("ğŸŒŸ æ€»ä½“è¯„ä»·ï¼šå›ç­”éå¸¸å…¨é¢å‡†ç¡®ï¼")
        elif score >= 0.7:
            feedback_parts.append("ğŸ‘ æ€»ä½“è¯„ä»·ï¼šå›ç­”åŸºæœ¬å‡†ç¡®ï¼Œæœ‰å°éƒ¨åˆ†å¯ä»¥å®Œå–„ã€‚")
        elif score >= 0.5:
            feedback_parts.append("ğŸ“š æ€»ä½“è¯„ä»·ï¼šç†è§£äº†éƒ¨åˆ†æ¦‚å¿µï¼Œå»ºè®®è¡¥å……å…³é”®è¦ç‚¹ã€‚")
        else:
            feedback_parts.append("ğŸ’ª æ€»ä½“è¯„ä»·ï¼šéœ€è¦åŠ å¼ºå­¦ä¹ ï¼Œå»ºè®®å¤ä¹ ç›¸å…³åŸºç¡€çŸ¥è¯†ã€‚")
        
        return "\n".join(feedback_parts)
    
    def _generate_encouragement(self, score: float) -> str:
        """ç”Ÿæˆé¼“åŠ±æ€§è¯„è¯­"""
        import random
        
        if score >= 0.9:
            category = "excellent"
        elif score >= 0.7:
            category = "good"
        elif score >= 0.4:
            category = "partial"
        else:
            category = "poor"
        
        return random.choice(self.encouragements[category])

# å…¨å±€è¯„åˆ†å™¨å®ä¾‹
theory_grader = TheoryQuestionGrader()

def grade_theory_answer(user_answer: str, correct_answer: str, 
                       question_content: str = "") -> Dict:
    """
    è¯„åˆ†ç†è®ºé¢˜ç­”æ¡ˆçš„ä¾¿æ·å‡½æ•°
    
    Returns:
        åŒ…å«è¯„åˆ†ç»“æœçš„å­—å…¸
    """
    result = theory_grader.grade_theory_question(
        user_answer, correct_answer, question_content
    )
    
    return {
        'score': result.score,
        'is_correct': result.is_correct,
        'partial_score': result.score,  # éƒ¨åˆ†åˆ†æ•°
        'feedback': result.feedback,
        'correct_keywords': result.correct_keywords,
        'missing_keywords': result.missing_keywords,
        'incorrect_parts': result.incorrect_parts,
        'encouragement': result.encouragement,
        'detailed_analysis': {
            'keyword_match_rate': len(result.correct_keywords) / (len(result.correct_keywords) + len(result.missing_keywords)) if (result.correct_keywords or result.missing_keywords) else 0,
            'total_keywords': len(result.correct_keywords) + len(result.missing_keywords),
            'matched_keywords_count': len(result.correct_keywords),
            'missing_keywords_count': len(result.missing_keywords)
        }
    }


def grade_fill_blank_answer(user_answer: str, correct_answer: str) -> Dict:
    """
    è¯„åˆ†å¡«ç©ºé¢˜ç­”æ¡ˆ
    
    å¡«ç©ºé¢˜éœ€è¦ç²¾ç¡®åŒ¹é…ï¼Œæ”¯æŒï¼š
    - å¤šä¸ªç­”æ¡ˆç”¨é€—å·ã€åˆ†å·æˆ–ç©ºæ ¼åˆ†éš”
    - å¿½ç•¥å¤§å°å†™
    - å¿½ç•¥å‰åç©ºæ ¼
    - åŒä¹‰è¯åŒ¹é…ï¼ˆéƒ¨åˆ†æƒ…å†µï¼‰
    
    Args:
        user_answer: ç”¨æˆ·ç­”æ¡ˆ
        correct_answer: æ ‡å‡†ç­”æ¡ˆ
        
    Returns:
        åŒ…å«è¯„åˆ†ç»“æœçš„å­—å…¸
    """
    if not user_answer or not user_answer.strip():
        return {
            'score': 0.0,
            'is_correct': False,
            'feedback': 'è¯·å¡«å†™ç­”æ¡ˆã€‚',
            'encouragement': 'å¡«ç©ºé¢˜éœ€è¦å‡†ç¡®çš„ç­”æ¡ˆï¼Œä»”ç»†æ€è€ƒä¸€ä¸‹ï¼',
            'correct_keywords': [],
            'missing_keywords': [correct_answer],
            'incorrect_parts': [],
            'detailed_analysis': {'match_details': 'ç­”æ¡ˆä¸ºç©º'}
        }
    
    # æ ‡å‡†åŒ–ç­”æ¡ˆ - å¤„ç†å¤šç§åˆ†éš”ç¬¦
    def normalize_answer(answer):
        # æ›¿æ¢å„ç§åˆ†éš”ç¬¦ä¸ºé€—å·
        answer = re.sub(r'[;ï¼›ã€\s]+', ',', answer.strip())
        # åˆ†å‰²å¹¶æ¸…ç†æ¯éƒ¨åˆ†
        parts = [part.strip().lower() for part in answer.split(',') if part.strip()]
        return parts
    
    user_parts = normalize_answer(user_answer)
    correct_parts = normalize_answer(correct_answer)
    
    print(f"å¡«ç©ºé¢˜è¯„åˆ† - ç”¨æˆ·ç­”æ¡ˆ: {user_parts}, æ ‡å‡†ç­”æ¡ˆ: {correct_parts}")
    
    # ç²¾ç¡®åŒ¹é…
    if user_parts == correct_parts:
        return {
            'score': 1.0,
            'is_correct': True,
            'feedback': 'å®Œå…¨æ­£ç¡®ï¼ç­”æ¡ˆå®Œç¾åŒ¹é…ã€‚',
            'encouragement': 'å¤ªæ£’äº†ï¼ä½ çš„ç­”æ¡ˆå®Œå…¨æ­£ç¡®ï¼',
            'correct_keywords': user_parts,
            'missing_keywords': [],
            'incorrect_parts': [],
            'detailed_analysis': {'match_details': 'å®Œå…¨åŒ¹é…'}
        }
    
    # éƒ¨åˆ†åŒ¹é…è®¡ç®—
    if len(correct_parts) == 0:
        return {
            'score': 0.0,
            'is_correct': False,
            'feedback': 'æ ‡å‡†ç­”æ¡ˆæ ¼å¼é”™è¯¯ã€‚',
            'encouragement': 'è¯·è”ç³»è€å¸ˆæ£€æŸ¥é¢˜ç›®ã€‚',
            'correct_keywords': [],
            'missing_keywords': [],
            'incorrect_parts': user_parts,
            'detailed_analysis': {'match_details': 'æ ‡å‡†ç­”æ¡ˆä¸ºç©º'}
        }
    
    # è®¡ç®—åŒ¹é…åº¦
    matched_count = 0
    matched_parts = []
    missing_parts = []
    incorrect_parts = []
    
    # æ£€æŸ¥æ¯ä¸ªæ ‡å‡†ç­”æ¡ˆéƒ¨åˆ†
    for correct_part in correct_parts:
        if correct_part in user_parts:
            matched_count += 1
            matched_parts.append(correct_part)
        else:
            missing_parts.append(correct_part)
    
    # æ£€æŸ¥ç”¨æˆ·å¤šä½™çš„ç­”æ¡ˆ
    for user_part in user_parts:
        if user_part not in correct_parts:
            incorrect_parts.append(user_part)
    
    # è®¡ç®—å¾—åˆ† - åŸºäºåŒ¹é…çš„æ¯”ä¾‹ï¼Œä½†æœ‰é”™è¯¯ç­”æ¡ˆä¼šæ‰£åˆ†
    base_score = matched_count / len(correct_parts)
    # é”™è¯¯ç­”æ¡ˆæ‰£åˆ†ï¼ˆæ¯ä¸ªé”™è¯¯ç­”æ¡ˆæ‰£é™¤10%ï¼‰
    penalty = len(incorrect_parts) * 0.1
    final_score = max(0.0, base_score - penalty)
    
    # åˆ¤æ–­æ˜¯å¦æ­£ç¡®ï¼ˆ90%ä»¥ä¸Šä¸”æ— é”™è¯¯ç­”æ¡ˆï¼‰
    is_correct = final_score >= 0.9 and len(incorrect_parts) == 0 and len(missing_parts) == 0
    
    # ç”Ÿæˆåé¦ˆ
    if final_score >= 0.8:
        feedback = f"å¾ˆæ¥è¿‘æ­£ç¡®ç­”æ¡ˆï¼åŒ¹é…äº† {matched_count}/{len(correct_parts)} ä¸ªç­”æ¡ˆã€‚"
    elif final_score >= 0.5:
        feedback = f"éƒ¨åˆ†æ­£ç¡®ï¼ŒåŒ¹é…äº† {matched_count}/{len(correct_parts)} ä¸ªç­”æ¡ˆã€‚"
    else:
        feedback = f"ç­”æ¡ˆéœ€è¦æ”¹è¿›ï¼Œä»…åŒ¹é…äº† {matched_count}/{len(correct_parts)} ä¸ªç­”æ¡ˆã€‚"
    
    if missing_parts:
        feedback += f" é—æ¼ï¼š{', '.join(missing_parts)}ã€‚"
    if incorrect_parts:
        feedback += f" å¤šä½™æˆ–é”™è¯¯ï¼š{', '.join(incorrect_parts)}ã€‚"
    
    # é¼“åŠ±æ€§è¯„è¯­
    if final_score >= 0.8:
        encouragement = "å¾ˆæ£’ï¼ç»§ç»­ä¿æŒè¿™æ ·çš„å‡†ç¡®æ€§ï¼"
    elif final_score >= 0.5:
        encouragement = "ä¸é”™çš„å°è¯•ï¼å†ä»”ç»†æ£€æŸ¥ä¸€ä¸‹ç­”æ¡ˆçš„å®Œæ•´æ€§ã€‚"
    else:
        encouragement = "æ²¡å…³ç³»ï¼Œå¡«ç©ºé¢˜éœ€è¦ç²¾ç¡®è®°å¿†ï¼Œå¤šç»ƒä¹ å‡ éå°±ä¼šç†Ÿæ‚‰äº†ï¼"
    
    return {
        'score': final_score,
        'is_correct': is_correct,
        'feedback': feedback,
        'encouragement': encouragement,
        'correct_keywords': matched_parts,
        'missing_keywords': missing_parts,
        'incorrect_parts': incorrect_parts,
        'detailed_analysis': {
            'match_details': f'åŒ¹é… {matched_count}/{len(correct_parts)}ï¼Œé”™è¯¯ {len(incorrect_parts)} ä¸ª',
            'user_parts': user_parts,
            'correct_parts': correct_parts
        }
    }