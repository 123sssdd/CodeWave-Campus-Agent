"""
AIé¢è¯•å®˜æœåŠ¡æ¨¡å—
é›†æˆè¯­éŸ³è½¬æ–‡å­—ã€å¤§è¯­è¨€æ¨¡å‹APIï¼Œå®ç°æ™ºèƒ½é¢è¯•å®˜åŠŸèƒ½
"""

import openai
import requests
import json
import base64
import os
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIInterviewerService:
    """AIé¢è¯•å®˜æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIé¢è¯•å®˜æœåŠ¡"""
        # å¤šç§å¤§æ¨¡å‹APIé…ç½®
        self.openai_api_key = os.getenv('OPENAI_API_KEY', '')
        self.openai_base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
        
        # é€šä¹‰åƒé—®APIé…ç½®
        self.qwen_api_key = os.getenv('QWEN_API_KEY', '')
        self.qwen_api_url = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'
        
        # ç™¾åº¦æ–‡å¿ƒä¸€è¨€APIé…ç½®
        self.baidu_api_key = os.getenv('BAIDU_API_KEY', '')
        self.baidu_secret_key = os.getenv('BAIDU_SECRET_KEY', '')
        self.baidu_app_id = os.getenv('BAIDU_APP_ID', '')
        
        # æ™ºè°±AIé…ç½®
        self.zhipu_api_key = os.getenv('ZHIPU_API_KEY', '')
        
        # ç¡®å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
        self.selected_model = self._select_available_model()
        
        # é¢è¯•å®˜è§’è‰²è®¾å®š
        self.interviewer_persona = {
            'role': 'system',
            'content': '''ä½ æ˜¯ä¸€ä½æ¥è‡ªé˜¿é‡Œå·´å·´/è…¾è®¯/å­—èŠ‚è·³åŠ¨çš„èµ„æ·±æŠ€æœ¯é¢è¯•å®˜ï¼Œå§“åå«å¼ æ€»ç›‘ã€‚ä½ æœ‰15å¹´çš„æŠ€æœ¯å’Œç®¡ç†ç»éªŒï¼Œé¢è¯•è¿‡ä¸Šåƒåå€™é€‰äººã€‚ä½ çš„ç‰¹ç‚¹ï¼š

**æ€§æ ¼ç‰¹å¾**ï¼š
- ğŸ¯ çŠ€åˆ©ç›´æ¥ï¼šä¸€é’ˆè§è¡€ï¼Œä¸ç»•å¼¯å­
- ğŸ˜ é€‚åº¦å¹½é»˜ï¼šä¼šç”¨å¹½é»˜ç¼“è§£ç´§å¼ ï¼Œä½†ä¸å¤±ä¸“ä¸š
- ğŸ” çœ¼å…‰æ¯’è¾£ï¼šèƒ½å¿«é€Ÿè¯†ç ´å€™é€‰äººçš„çœŸå®æ°´å¹³
- ğŸ’¡ å®ç”¨ä¸»ä¹‰ï¼šå…³æ³¨å®é™…å·¥ä½œèƒ½åŠ›ï¼Œä¸åªæ˜¯ç†è®ºçŸ¥è¯†

**é¢è¯•é£æ ¼**ï¼š
- å¯¹ä¼˜ç§€å›ç­”ï¼šã€Œä¸é”™ï¼Œçœ‹æ¥ä½ ç¡®å®æœ‰ä¸¤æŠŠåˆ·å­ã€‚é‚£æˆ‘é—®ä¸ªæ›´æ·±å…¥çš„...ã€
- å¯¹ä¸€èˆ¬å›ç­”ï¼šã€Œå—¯ï¼ŒåŸºç¡€è¿˜è¡Œï¼Œä½†åœ¨æˆ‘ä»¬å…¬å¸è¿™ä¸ªæ°´å¹³å¯èƒ½è¿˜ä¸å¤Ÿã€‚ä½ èƒ½è¯´è¯´...ã€
- å¯¹é”™è¯¯å›ç­”ï¼šã€Œå“ï¼Œè¿™ä¸ªç†è§£æœ‰é—®é¢˜å•Šã€‚åœ¨é˜¿é‡Œæˆ‘ä»¬ç»å¸¸é‡åˆ°è¿™ç§æƒ…å†µï¼Œæ­£ç¡®çš„åšæ³•æ˜¯...ã€
- å¯¹ç­”éæ‰€é—®ï¼šã€Œç­‰ç­‰ï¼Œä½ è¿™æ˜¯åœ¨å›é¿æˆ‘çš„é—®é¢˜å§ï¼Ÿæˆ‘é—®çš„æ˜¯Aï¼Œä½ ç­”çš„æ˜¯Bã€‚å†æ¥ä¸€æ¬¡ï¼Ÿã€
- å¯¹å¼€ç©ç¬‘ï¼šã€Œå“ˆå“ˆï¼Œå¹½é»˜æ„Ÿä¸é”™ï¼Œä½†é¢è¯•è¿˜æ˜¯ä¸¥è‚ƒç‚¹ã€‚åˆšæ‰é‚£ä¸ªé—®é¢˜ä½ å†è®¤çœŸå›ç­”ä¸€ä¸‹ã€‚ã€

**å…¬å¸åœºæ™¯é—®é¢˜**ï¼ˆä¼šéšæœºæå‡ºï¼‰ï¼š
1. **é˜¿é‡Œåœºæ™¯**ï¼šã€Œå‡è®¾ä½ åœ¨æ·˜å®å·¥ä½œï¼ŒåŒ11å½“å¤©ç³»ç»ŸQPSçªç„¶é£™å‡10å€ï¼Œä½ ä¼šæ€ä¹ˆå¤„ç†ï¼Ÿã€
2. **è…¾è®¯åœºæ™¯**ï¼šã€Œå¾®ä¿¡æœ‰10äº¿ç”¨æˆ·ï¼Œå¦‚æœè®©ä½ è®¾è®¡æœ‹å‹åœˆçš„æ¨èç®—æ³•ï¼Œä½ ä¼šè€ƒè™‘å“ªäº›å› ç´ ï¼Ÿã€
3. **å­—èŠ‚åœºæ™¯**ï¼šã€ŒæŠ–éŸ³çš„æ¨èç³»ç»Ÿæ¯å¤©è¦å¤„ç†å‡ äº¿ä¸ªè§†é¢‘ï¼Œå¦‚ä½•ä¿è¯æ¨èçš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ï¼Ÿã€
4. **äº§å“ç†è§£**ï¼šã€Œä½ è§‰å¾—æˆ‘ä»¬å…¬å¸çš„æ ¸å¿ƒäº§å“æœ‰ä»€ä¹ˆå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿç»™ä¸ªå…·ä½“å»ºè®®ã€‚ã€
5. **æŠ€æœ¯æŒ‘æˆ˜**ï¼šã€Œåœ¨ä½ çœ‹æ¥ï¼Œæˆ‘ä»¬å…¬å¸é¢ä¸´çš„æœ€å¤§æŠ€æœ¯æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿä½ ä¼šæ€ä¹ˆè§£å†³ï¼Ÿã€

**è¯„ä»·æ ‡å‡†**ï¼š
- æŠ€æœ¯æ·±åº¦ï¼ˆ40%ï¼‰ï¼šä¸åªè¦çŸ¥é“æ˜¯ä»€ä¹ˆï¼Œæ›´è¦çŸ¥é“ä¸ºä»€ä¹ˆ
- å®é™…ç»éªŒï¼ˆ30%ï¼‰ï¼šæœ‰æ²¡æœ‰çœŸæ­£åšè¿‡é¡¹ç›®ï¼Œè¸©è¿‡å‘
- æ€ç»´é€»è¾‘ï¼ˆ20%ï¼‰ï¼šåˆ†æé—®é¢˜çš„æ€è·¯æ˜¯å¦æ¸…æ™°
- å­¦ä¹ èƒ½åŠ›ï¼ˆ10%ï¼‰ï¼šé‡åˆ°ä¸ä¼šçš„é—®é¢˜ï¼Œå­¦ä¹ æ€åº¦å¦‚ä½•

**å›åº”æ ¼å¼**ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªJSONæ ¼å¼ï¼‰ï¼š
{
    "evaluation": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/éœ€è¦æ”¹è¿›",
    "feedback": "çŠ€åˆ©è€Œå¹½é»˜çš„å…·ä½“åé¦ˆï¼Œä½“ç°é¢è¯•å®˜ä¸ªæ€§",
    "follow_up": "è¿½é—®é—®é¢˜æˆ–ä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆå¯é€‰ï¼‰",
    "suggestions": "å®ç”¨çš„æ”¹è¿›å»ºè®®ï¼ˆå¯é€‰ï¼‰",
    "tone": "é¼“åŠ±/ä¸­æ€§/ä¸¥è‚ƒ/å¹½é»˜",
    "company_scenario": "å¦‚æœåˆé€‚ï¼Œæå‡ºå…¬å¸åœºæ™¯é—®é¢˜ï¼ˆå¯é€‰ï¼‰"
}

è®°ä½ï¼šä½ æ˜¯å¼ æ€»ç›‘ï¼Œè¦ä½“ç°å‡ºèµ„æ·±é¢è¯•å®˜çš„çŠ€åˆ©å’Œå¹½é»˜ï¼Œè®©å€™é€‰äººæ„Ÿå—åˆ°çœŸå®çš„å¤§å‚é¢è¯•æ°›å›´ï¼'''
        }
    
    def _select_available_model(self):
        """é€‰æ‹©å¯ç”¨çš„å¤§æ¨¡å‹"""
        if self.qwen_api_key:
            logger.info("ä½¿ç”¨é€šä¹‰åƒé—®æ¨¡å‹")
            return 'qwen'
        elif self.baidu_api_key and self.baidu_secret_key:
            logger.info("ä½¿ç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¨¡å‹")
            return 'baidu'
        elif self.zhipu_api_key:
            logger.info("ä½¿ç”¨æ™ºè°±AIæ¨¡å‹")
            return 'zhipu'
        elif self.openai_api_key:
            logger.info("ä½¿ç”¨OpenAIæ¨¡å‹")
            return 'openai'
        else:
            logger.info("æ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å‹")
            return 'mock'
    
    def speech_to_text_web_api(self, audio_blob_url: str) -> str:
        """
        ä½¿ç”¨Web Speech APIè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼ˆå‰ç«¯å®ç°ï¼‰
        è¿™é‡Œæä¾›åç«¯æ¥å£æ”¯æŒ
        """
        # è¿™ä¸ªæ–¹æ³•ä¸»è¦æ˜¯ä¸ºäº†æä¾›æ¥å£ï¼Œå®é™…è½¬æ¢åœ¨å‰ç«¯å®Œæˆ
        return ""
    
    def speech_to_text_baidu(self, audio_data: bytes, audio_format: str = 'wav') -> str:
        """
        ä½¿ç”¨ç™¾åº¦è¯­éŸ³è¯†åˆ«APIè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
        """
        if not all([self.baidu_app_id, self.baidu_api_key, self.baidu_secret_key]):
            logger.warning("ç™¾åº¦è¯­éŸ³è¯†åˆ«APIé…ç½®ä¸å®Œæ•´")
            return ""
        
        try:
            # è·å–access_token
            token_url = "https://aip.baidubce.com/oauth/2.0/token"
            token_params = {
                'grant_type': 'client_credentials',
                'client_id': self.baidu_api_key,
                'client_secret': self.baidu_secret_key
            }
            
            token_response = requests.post(token_url, params=token_params)
            access_token = token_response.json().get('access_token')
            
            if not access_token:
                logger.error("è·å–ç™¾åº¦API access_tokenå¤±è´¥")
                return ""
            
            # è¯­éŸ³è¯†åˆ«è¯·æ±‚
            asr_url = f"https://vop.baidu.com/server_api?access_token={access_token}"
            
            # éŸ³é¢‘æ•°æ®base64ç¼–ç 
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            asr_data = {
                'format': audio_format,
                'rate': 16000,
                'channel': 1,
                'cuid': 'python_client',
                'token': access_token,
                'speech': audio_base64,
                'len': len(audio_data)
            }
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            response = requests.post(asr_url, data=json.dumps(asr_data), headers=headers)
            result = response.json()
            
            if result.get('err_no') == 0:
                return result.get('result', [''])[0]
            else:
                logger.error(f"ç™¾åº¦è¯­éŸ³è¯†åˆ«é”™è¯¯: {result.get('err_msg')}")
                return ""
                
        except Exception as e:
            logger.error(f"ç™¾åº¦è¯­éŸ³è¯†åˆ«å¼‚å¸¸: {str(e)}")
            return ""
    
    def get_ai_response(self, question: str, user_answer: str, context: List[Dict] = None) -> Dict:
        """
        ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è·å–AIé¢è¯•å®˜å›åº”
        
        Args:
            question: é¢è¯•é—®é¢˜
            user_answer: ç”¨æˆ·å›ç­”
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            AIé¢è¯•å®˜çš„å›åº”
        """
        try:
            # æ„å»ºæç¤ºè¯
            current_prompt = f"""
é¢è¯•é—®é¢˜ï¼š{question}

å€™é€‰äººå›ç­”ï¼š{user_answer}

è¯·ä½œä¸ºå¼ æ€»ç›‘ï¼ˆèµ„æ·±æŠ€æœ¯é¢è¯•å®˜ï¼‰å¯¹è¿™ä¸ªå›ç­”è¿›è¡Œè¯„ä»·å’Œåé¦ˆã€‚è¦æ±‚ï¼š
1. çŠ€åˆ©ç›´æ¥ï¼Œä¸€é’ˆè§è¡€
2. é€‚åº¦å¹½é»˜ï¼Œä½†ä¸å¤±ä¸“ä¸š
3. æ ¹æ®å›ç­”è´¨é‡å†³å®šæ˜¯å¦è¿½é—®
4. å¯ä»¥æå‡ºå…¬å¸åœºæ™¯é—®é¢˜

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼š
{{
    "evaluation": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/éœ€è¦æ”¹è¿›",
    "feedback": "çŠ€åˆ©è€Œå¹½é»˜çš„å…·ä½“åé¦ˆ",
    "follow_up": "è¿½é—®é—®é¢˜ï¼ˆå¯é€‰ï¼‰",
    "suggestions": "æ”¹è¿›å»ºè®®ï¼ˆå¯é€‰ï¼‰",
    "tone": "é¼“åŠ±/ä¸­æ€§/ä¸¥è‚ƒ/å¹½é»˜",
    "company_scenario": "å…¬å¸åœºæ™¯é—®é¢˜ï¼ˆå¯é€‰ï¼‰"
}}
"""
            
            # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è°ƒç”¨ç›¸åº”API
            if self.selected_model == 'qwen':
                return self._call_qwen_api(current_prompt)
            elif self.selected_model == 'baidu':
                return self._call_baidu_api(current_prompt)
            elif self.selected_model == 'zhipu':
                return self._call_zhipu_api(current_prompt)
            elif self.selected_model == 'openai':
                return self._call_openai_api(current_prompt, context)
            else:
                return self._get_mock_response(question, user_answer)
                
        except Exception as e:
            logger.error(f"AIé¢è¯•å®˜å›åº”ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._get_mock_response(question, user_answer)
    
    def _call_qwen_api(self, prompt: str) -> Dict:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        try:
            headers = {
                'Authorization': f'Bearer {self.qwen_api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                "model": "qwen-turbo",
                "input": {
                    "messages": [
                        {"role": "user", "content": prompt}
                    ]
                },
                "parameters": {
                    "temperature": 0.7,
                    "max_tokens": 800
                }
            }
            
            response = requests.post(self.qwen_api_url, headers=headers, json=data)
            result = response.json()
            
            if response.status_code == 200 and 'output' in result:
                ai_response = result['output']['text']
                return self._parse_json_response(ai_response)
            else:
                logger.error(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {result}")
                return self._get_mock_response("", "")
                
        except Exception as e:
            logger.error(f"é€šä¹‰åƒé—®APIå¼‚å¸¸: {str(e)}")
            return self._get_mock_response("", "")
    
    def _call_baidu_api(self, prompt: str) -> Dict:
        """è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€API"""
        try:
            # è·å–access_token
            token_url = "https://aip.baidubce.com/oauth/2.0/token"
            token_params = {
                'grant_type': 'client_credentials',
                'client_id': self.baidu_api_key,
                'client_secret': self.baidu_secret_key
            }
            
            token_response = requests.post(token_url, params=token_params)
            access_token = token_response.json().get('access_token')
            
            if not access_token:
                logger.error("è·å–ç™¾åº¦API access_tokenå¤±è´¥")
                return self._get_mock_response("", "")
            
            # è°ƒç”¨æ–‡å¿ƒä¸€è¨€API
            api_url = f"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token={access_token}"
            
            headers = {'Content-Type': 'application/json'}
            data = {
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "max_output_tokens": 800
            }
            
            response = requests.post(api_url, headers=headers, json=data)
            result = response.json()
            
            if response.status_code == 200 and 'result' in result:
                ai_response = result['result']
                return self._parse_json_response(ai_response)
            else:
                logger.error(f"ç™¾åº¦æ–‡å¿ƒä¸€è¨€APIè°ƒç”¨å¤±è´¥: {result}")
                return self._get_mock_response("", "")
                
        except Exception as e:
            logger.error(f"ç™¾åº¦æ–‡å¿ƒä¸€è¨€APIå¼‚å¸¸: {str(e)}")
            return self._get_mock_response("", "")
    
    def _call_zhipu_api(self, prompt: str) -> Dict:
        """è°ƒç”¨æ™ºè°±AI API"""
        try:
            import jwt
            import time
            
            # ç”ŸæˆJWT token
            def generate_token(apikey: str, exp_seconds: int = 3600):
                try:
                    id, secret = apikey.split(".")
                except Exception:
                    raise Exception("invalid apikey")
                
                payload = {
                    "iss": id,
                    "exp": int(round(time.time() * 1000)) + exp_seconds * 1000,
                    "timestamp": int(round(time.time() * 1000)),
                }
                
                return jwt.encode(payload, secret, algorithm="HS256", headers={"alg": "HS256", "sign_type": "SIGN"})
            
            token = generate_token(self.zhipu_api_key)
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Content-Type': 'application/json'
            }
            
            data = {
                "model": "glm-4",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "max_tokens": 800
            }
            
            response = requests.post("https://open.bigmodel.cn/api/paas/v4/chat/completions", headers=headers, json=data)
            result = response.json()
            
            if response.status_code == 200 and 'choices' in result:
                ai_response = result['choices'][0]['message']['content']
                return self._parse_json_response(ai_response)
            else:
                logger.error(f"æ™ºè°±AI APIè°ƒç”¨å¤±è´¥: {result}")
                return self._get_mock_response("", "")
                
        except Exception as e:
            logger.error(f"æ™ºè°±AI APIå¼‚å¸¸: {str(e)}")
            return self._get_mock_response("", "")
    
    def _call_openai_api(self, prompt: str, context: List[Dict] = None) -> Dict:
        """è°ƒç”¨OpenAI API"""
        try:
            messages = [self.interviewer_persona]
            if context:
                messages.extend(context)
            messages.append({'role': 'user', 'content': prompt})
            
            client = openai.OpenAI(
                api_key=self.openai_api_key,
                base_url=self.openai_base_url
            )
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=800,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            return self._parse_json_response(ai_response)
            
        except Exception as e:
            logger.error(f"OpenAI APIå¼‚å¸¸: {str(e)}")
            return self._get_mock_response("", "")
    
    def _parse_json_response(self, ai_response: str) -> Dict:
        """è§£æAIæ¨¡å‹è¿”å›çš„JSONå“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            return json.loads(ai_response)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯æ ‡å‡†JSONï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼ŒåŒ…è£…æˆæ ‡å‡†æ ¼å¼
            return {
                'evaluation': 'ä¸€èˆ¬',
                'feedback': ai_response,
                'follow_up': '',
                'suggestions': '',
                'tone': 'ä¸­æ€§'
            }
    
    def _get_mock_response(self, question: str, user_answer: str) -> Dict:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿçš„AIé¢è¯•å®˜å›åº”ï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
        å¼ æ€»ç›‘çš„çŠ€åˆ©é£æ ¼æ¨¡æ‹Ÿç‰ˆæœ¬
        """
        import random
        
        answer_lower = user_answer.lower()
        
        # å…¬å¸åœºæ™¯é—®é¢˜åº“
        company_scenarios = [
            "å‡è®¾ä½ åœ¨é˜¿é‡Œå·¥ä½œï¼ŒåŒ11å½“å¤©ç³»ç»Ÿçªç„¶å´©äº†ï¼Œä½ ç¬¬ä¸€æ—¶é—´ä¼šåšä»€ä¹ˆï¼Ÿ",
            "å¦‚æœè®©ä½ ä¼˜åŒ–å¾®ä¿¡æœ‹å‹åœˆçš„åŠ è½½é€Ÿåº¦ï¼Œä½ ä¼šä»å“ªå‡ ä¸ªæ–¹é¢å…¥æ‰‹ï¼Ÿ",
            "æŠ–éŸ³æ¯å¤©æ–°å¢å‡ åƒä¸‡ä¸ªè§†é¢‘ï¼Œå¦‚ä½•ä¿è¯æ¨èç®—æ³•ä¸ä¼šæ¨é‡å¤å†…å®¹ï¼Ÿ",
            "ä½ è§‰å¾—æ·˜å®çš„æœç´¢ç»“æœæ’åºæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿç»™ä¸ªæ”¹è¿›æ–¹æ¡ˆã€‚",
            "å‡è®¾ä½ æ˜¯è…¾è®¯äº‘çš„æ¶æ„å¸ˆï¼Œå¦‚ä½•è®¾è®¡ä¸€ä¸ªèƒ½æ‰¿è½½æ˜¥æ™šçº¢åŒ…çš„ç³»ç»Ÿï¼Ÿ"
        ]
        
        if not user_answer.strip():
            responses = [
                "å¼ æ€»ç›‘çš±äº†çš±çœ‰ï¼šå°ä¼™å­ï¼Œè¿™æ˜¯é¢è¯•ä¸æ˜¯å†¥æƒ³ï¼Œè¯´ç‚¹ä»€ä¹ˆå§ï¼Ÿ",
                "å“¦è±ï¼Œè¿™æ˜¯å‡†å¤‡ç”¨æ²‰é»˜æ¥å¾æœæˆ‘å—ï¼Ÿæˆ‘ä»¬é˜¿é‡Œä¸éœ€è¦å“‘å·´å·¥ç¨‹å¸ˆå“¦ã€‚",
                "emmm...ä½ è¿™æ˜¯åœ¨æ€è€ƒäººç”Ÿå—ï¼Ÿæˆ‘é—®çš„æ˜¯æŠ€æœ¯é—®é¢˜ï¼Œä¸æ˜¯å“²å­¦é—®é¢˜ã€‚"
            ]
            return {
                'evaluation': 'éœ€è¦æ”¹è¿›',
                'feedback': random.choice(responses),
                'follow_up': 'æ¥æ¥æ¥ï¼Œéšä¾¿è¯´ç‚¹ä»€ä¹ˆï¼Œå“ªæ€•æ˜¯é”™çš„ä¹Ÿæ¯”ä¸è¯´å¼ºã€‚',
                'suggestions': 'é¢è¯•å®˜æœ€æ€•çš„å°±æ˜¯å€™é€‰äººä¸è¯´è¯ï¼Œæœ‰æƒ³æ³•å°±å¤§èƒ†è¯´å‡ºæ¥ã€‚',
                'tone': 'å¹½é»˜'
            }
        
        if any(word in answer_lower for word in ['ä¸çŸ¥é“', 'ä¸ä¼š', 'æ²¡æœ‰ç»éªŒ', 'æ²¡åšè¿‡']):
            responses = [
                "è¯šå®æ˜¯å¥½äº‹ï¼Œä½†'ä¸çŸ¥é“'å¯ä¸æ˜¯ä¸‡èƒ½ç­”æ¡ˆã€‚åœ¨æˆ‘ä»¬å…¬å¸ï¼Œé‡åˆ°ä¸ä¼šçš„é—®é¢˜è¦å­¦ä¼šåˆ†æã€‚",
                "å—¯ï¼Œè‡³å°‘ä½ è¯šå®ã€‚ä½†åœ¨å­—èŠ‚è·³åŠ¨ï¼Œæˆ‘ä»¬æ›´å–œæ¬¢'è™½ç„¶æ²¡åšè¿‡ï¼Œä½†æˆ‘è§‰å¾—å¯ä»¥è¿™æ ·...'çš„æ€åº¦ã€‚",
                "å“ˆå“ˆï¼Œå¦‚æœä»€ä¹ˆéƒ½ä¼šé‚£è¿˜è¦åŸ¹è®­å¹²å˜›ï¼Ÿè¯´è¯´ä½ çš„æ€è·¯ï¼Œé”™äº†ä¹Ÿæ²¡å…³ç³»ã€‚"
            ]
            return {
                'evaluation': 'éœ€è¦æ”¹è¿›',
                'feedback': random.choice(responses),
                'follow_up': random.choice(company_scenarios),
                'suggestions': 'é‡åˆ°ä¸ä¼šçš„é—®é¢˜ï¼Œå¯ä»¥è¯´è¯´ä½ ä¼šæ€ä¹ˆå»å­¦ä¹ å’Œè§£å†³ã€‚',
                'tone': 'é¼“åŠ±'
            }
        
        if any(word in answer_lower for word in ['å“ˆå“ˆ', 'å¼€ç©ç¬‘', 'æç¬‘', 'å‘µå‘µ']):
            responses = [
                "å“ˆå“ˆï¼Œå¹½é»˜æ„Ÿä¸é”™ï¼ä½†å’±ä»¬è¿˜æ˜¯èŠèŠæŠ€æœ¯å§ï¼Œæˆ‘å¯æ˜¯æŠ€æœ¯å‡ºèº«çš„ã€‚",
                "æ®µå­æ‰‹å•Šï¼Ÿæˆ‘ä»¬å…¬å¸ç¡®å®éœ€è¦æ´»è·ƒæ°”æ°›çš„äººï¼Œä½†æŠ€æœ¯ä¹Ÿå¾—è¿‡å…³æ‰è¡Œã€‚",
                "ç¬‘å®¹å¾ˆç¿çƒ‚ï¼Œé‚£æŠ€æœ¯æ°´å¹³æ˜¯ä¸æ˜¯ä¹Ÿè¿™ä¹ˆäº®çœ¼å‘¢ï¼Ÿ"
            ]
            return {
                'evaluation': 'ä¸€èˆ¬',
                'feedback': random.choice(responses),
                'follow_up': 'æ¥ä¸ªæ­£ç»å›ç­”ï¼Œè®©æˆ‘çœ‹çœ‹ä½ çš„çœŸæœ¬äº‹ã€‚',
                'suggestions': 'é€‚åº¦å¹½é»˜å¯ä»¥ï¼Œä½†è¦æŠŠæ¡å¥½åº¦ï¼Œé¢è¯•å®˜æ›´å…³æ³¨ä½ çš„ä¸“ä¸šèƒ½åŠ›ã€‚',
                'tone': 'å¹½é»˜'
            }
        
        if len(user_answer) < 20:
            responses = [
                "è¿™å›ç­”æœ‰ç‚¹ç®€å•å•Šï¼Œåœ¨é˜¿é‡Œæˆ‘ä»¬å–œæ¬¢æœ‰æ·±åº¦çš„æ€è€ƒã€‚èƒ½è¯¦ç»†è¯´è¯´å—ï¼Ÿ",
                "emmm...è¿™ä¸ªå›ç­”è®©æˆ‘æƒ³èµ·äº†å°å­¦ç”Ÿçš„ä½œæ–‡ï¼Œèƒ½å†ä¸°å¯Œä¸€ç‚¹å—ï¼Ÿ",
                "çœ‹æ¥ä½ æ˜¯ä¸ªæƒœå­—å¦‚é‡‘çš„äººï¼Œä½†é¢è¯•æ—¶è¿˜æ˜¯å¤šè¯´ç‚¹æ¯”è¾ƒå¥½ã€‚"
            ]
            return {
                'evaluation': 'ä¸€èˆ¬',
                'feedback': random.choice(responses),
                'follow_up': 'èƒ½ä¸¾ä¸ªå…·ä½“çš„ä¾‹å­å—ï¼Ÿæˆ–è€…è¯´è¯´ä½ çš„å®é™…ç»éªŒï¼Ÿ',
                'suggestions': 'å›ç­”é—®é¢˜æ—¶ï¼Œå°½é‡ç»“åˆå…·ä½“ä¾‹å­ï¼Œè¿™æ ·æ›´æœ‰è¯´æœåŠ›ã€‚',
                'tone': 'ä¸­æ€§'
            }
        
        if any(word in answer_lower for word in ['é¡¹ç›®', 'ç»éªŒ', 'å®é™…', 'é‡åˆ°è¿‡']):
            responses = [
                "ä¸é”™ï¼Œçœ‹æ¥ä½ ç¡®å®æœ‰å®æˆ˜ç»éªŒã€‚é‚£æˆ‘é—®ä¸ªæ›´æ·±å…¥çš„é—®é¢˜...",
                "å—¯ï¼Œæœ‰é¡¹ç›®ç»éªŒæ˜¯å¥½äº‹ã€‚ä½†åœ¨æˆ‘ä»¬å…¬å¸ï¼Œå…‰æœ‰ç»éªŒè¿˜ä¸å¤Ÿï¼Œè¿˜è¦æœ‰æ·±åº¦æ€è€ƒã€‚",
                "é¡¹ç›®ç»éªŒå¾ˆé‡è¦ï¼Œä½†æˆ‘æ›´æƒ³çŸ¥é“ä½ ä»ä¸­å­¦åˆ°äº†ä»€ä¹ˆã€‚"
            ]
            return {
                'evaluation': 'è‰¯å¥½',
                'feedback': random.choice(responses),
                'follow_up': random.choice(company_scenarios),
                'suggestions': 'ç»§ç»­ä¿æŒï¼Œç»“åˆå®é™…é¡¹ç›®ç»éªŒå›ç­”é—®é¢˜æ˜¯å¾ˆå¥½çš„ä¹ æƒ¯ã€‚',
                'tone': 'é¼“åŠ±'
            }
        
        # é»˜è®¤å›åº” - æ›´åŠ çŠ€åˆ©
        responses = [
            "å›ç­”è¿˜ç®—ä¸­è§„ä¸­çŸ©ï¼Œä½†åœ¨å¤§å‚é¢è¯•ä¸­ï¼Œä¸­è§„ä¸­çŸ©å¾€å¾€æ„å‘³ç€å¹³åº¸ã€‚",
            "åŸºç¡€ç†è®ºæŒæ¡å¾—ä¸é”™ï¼Œä½†æˆ‘æ›´æƒ³å¬å¬ä½ çš„ç‹¬ç‰¹è§è§£ã€‚",
            "å—¯ï¼Œæ•™ç§‘ä¹¦å¼çš„å›ç­”ã€‚é‚£å®é™…å·¥ä½œä¸­ä½ ä¼šæ€ä¹ˆå¤„ç†å‘¢ï¼Ÿ"
        ]
        
        return {
            'evaluation': 'ä¸€èˆ¬',
            'feedback': random.choice(responses),
            'follow_up': random.choice(company_scenarios),
            'suggestions': 'å°è¯•ä»å®é™…åº”ç”¨åœºæ™¯çš„è§’åº¦æ¥æ€è€ƒé—®é¢˜ï¼Œè¿™æ ·æ›´æœ‰ä»·å€¼ã€‚',
            'tone': 'ä¸­æ€§',
            'company_scenario': random.choice(company_scenarios)
        }
    
    def analyze_interview_performance(self, qa_history: List[Dict]) -> Dict:
        """
        åˆ†ææ•´åœºé¢è¯•çš„è¡¨ç°
        
        Args:
            qa_history: é—®ç­”å†å²è®°å½•
            
        Returns:
            é¢è¯•è¡¨ç°åˆ†ææŠ¥å‘Š
        """
        if not qa_history:
            return {
                'overall_score': 0,
                'strengths': [],
                'weaknesses': ['æœªå®Œæˆä»»ä½•é—®ç­”'],
                'recommendations': ['å»ºè®®é‡æ–°è¿›è¡Œé¢è¯•']
            }
        
        # ç»Ÿè®¡å„ç§è¯„ä»·
        evaluations = [qa.get('ai_response', {}).get('evaluation', 'ä¸€èˆ¬') for qa in qa_history]
        
        excellent_count = evaluations.count('ä¼˜ç§€')
        good_count = evaluations.count('è‰¯å¥½')
        average_count = evaluations.count('ä¸€èˆ¬')
        poor_count = evaluations.count('éœ€è¦æ”¹è¿›')
        
        total_questions = len(evaluations)
        
        # è®¡ç®—æ€»åˆ†
        score = (excellent_count * 4 + good_count * 3 + average_count * 2 + poor_count * 1) / total_questions
        overall_score = min(100, int(score * 25))
        
        # åˆ†æä¼˜åŠ¿å’Œä¸è¶³
        strengths = []
        weaknesses = []
        recommendations = []
        
        if excellent_count > total_questions * 0.3:
            strengths.append('æŠ€æœ¯ç†è§£æ·±å…¥ï¼Œå›ç­”è´¨é‡é«˜')
        if good_count > total_questions * 0.4:
            strengths.append('åŸºç¡€çŸ¥è¯†æ‰å®')
        if poor_count < total_questions * 0.2:
            strengths.append('æ•´ä½“è¡¨ç°ç¨³å®š')
        
        if poor_count > total_questions * 0.3:
            weaknesses.append('éƒ¨åˆ†é—®é¢˜å›ç­”ä¸å¤Ÿå‡†ç¡®')
            recommendations.append('å»ºè®®åŠ å¼ºåŸºç¡€çŸ¥è¯†å­¦ä¹ ')
        if average_count > total_questions * 0.5:
            weaknesses.append('å›ç­”æ·±åº¦æœ‰å¾…æå‡')
            recommendations.append('å»ºè®®å¤šè¿›è¡Œå®è·µé¡¹ç›®ç»éªŒç§¯ç´¯')
        
        if not strengths:
            strengths.append('å‚ä¸äº†å®Œæ•´çš„é¢è¯•æµç¨‹')
        if not recommendations:
            recommendations.append('ç»§ç»­ä¿æŒå­¦ä¹ çƒ­æƒ…ï¼Œå¤šåšç»ƒä¹ ')
        
        return {
            'overall_score': overall_score,
            'question_count': total_questions,
            'excellent_count': excellent_count,
            'good_count': good_count,
            'average_count': average_count,
            'poor_count': poor_count,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'recommendations': recommendations
        }

# å…¨å±€AIé¢è¯•å®˜æœåŠ¡å®ä¾‹
ai_interviewer = AIInterviewerService()
